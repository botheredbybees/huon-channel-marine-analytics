#!/usr/bin/env python3\n\"\"\"\nSearches for metadata.xml files in the nested AODN directory structure.\nPattern: AODN_data/[dataset-name]/[UUID]/metadata/metadata.xml\n\nKey insight: The directory names ARE the UUIDs (from AODN catalogue).\nWe then map these to database UUIDs using dataset titles.\n\nUsage:\n    python scripts/find_metadata_xml_files.py\n\"\"\"\n\nimport os\nimport sys\nfrom pathlib import Path\nimport re\n\ndef find_metadata_xml_files(root_path=\"AODN_data\"):\n    \"\"\"Recursively find all metadata.xml files in directory tree.\"\"\"\n    metadata_files = []\n    \n    root = Path(root_path)\n    if not root.exists():\n        print(f\"ERROR: Root path does not exist: {root_path}\")\n        return metadata_files\n    \n    # Find all metadata.xml files recursively\n    for xml_file in root.rglob('metadata.xml'):\n        metadata_files.append(xml_file)\n    \n    return sorted(metadata_files)\n\ndef extract_dataset_info(xml_path):\n    \"\"\"Extract dataset name and UUID from the path.\n    \n    Path structure: AODN_data/[Dataset Name]/[UUID]/metadata/metadata.xml\n    \"\"\"\n    parts = xml_path.parts\n    \n    # Structure: (..., 'AODN_data', 'Dataset Name', 'UUID', 'metadata', 'metadata.xml')\n    if len(parts) >= 5 and parts[-2] == 'metadata':\n        uuid = parts[-3]  # The UUID directory name\n        dataset_name = parts[-4]  # The dataset directory name\n        return dataset_name, uuid\n    return None, None\n\ndef extract_title_from_metadata(xml_path):\n    \"\"\"Extract the dataset title from the metadata.xml file.\n    \n    Looking for a title element early in the XML.\n    \"\"\"\n    try:\n        with open(xml_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read(5000)  # Read first 5KB\n            \n            # Look for title patterns in XML\n            # Common patterns: <gco:CharacterString>, <CharacterString>, or plain text after a title tag\n            title_patterns = [\n                r'<gco:CharacterString>([^<]+The Australian Chlorophyll[^<]*)</gco:CharacterString>',\n                r'<gco:CharacterString>([^<]+Phytoplankton[^<]*)</gco:CharacterString>',\n                r'<gco:CharacterString>([^<]+Seagrass[^<]*)</gco:CharacterString>',\n                r'<gco:CharacterString>([^<]{10,200}?)</gco:CharacterString>',  # Generic title\n            ]\n            \n            for pattern in title_patterns:\n                match = re.search(pattern, content)\n                if match:\n                    title = match.group(1).strip()\n                    if len(title) > 5:\n                        return title\n        \n        return None\n    except Exception as e:\n        return None\n\ndef main():\n    print(\"\\n\" + \"=\"*100)\n    print(\"SEARCHING FOR METADATA.XML FILES IN AODN DIRECTORY\")\n    print(\"=\"*100)\n    \n    # Find all metadata.xml files\n    xml_files = find_metadata_xml_files()\n    \n    print(f\"\\nFound {len(xml_files)} metadata.xml files\\n\")\n    \n    # Extract dataset info from each file path\n    results = []\n    for i, xml_path in enumerate(xml_files, 1):\n        dataset_name, uuid = extract_dataset_info(xml_path)\n        title = extract_title_from_metadata(xml_path) or \"(not extracted)\"\n        \n        if uuid:\n            results.append({\n                'number': i,\n                'uuid': uuid,\n                'dataset_dir': dataset_name,\n                'path': str(xml_path),\n                'title': title\n            })\n            \n            print(f\"{i}. UUID: {uuid}\")\n            print(f\"   Dataset: {dataset_name}\")\n            print(f\"   File: {xml_path}\")\n            print(f\"   Title: {title}\")\n            print()\n    \n    # Summary\n    print(\"\\n\" + \"=\"*100)\n    print(\"SUMMARY\")\n    print(\"=\"*100)\n    print(f\"Total metadata.xml files found: {len(results)}\")\n    print(f\"UUIDs extracted from directory names: {len(results)}\")\n    \n    # Save to CSV for inspection\n    import csv\n    csv_path = Path('metadata_files_found.csv')\n    with open(csv_path, 'w', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=['number', 'uuid', 'dataset_dir', 'title', 'path'])\n        writer.writeheader()\n        writer.writerows(results)\n    \n    print(f\"\\nResults saved to: {csv_path}\")\n    \n    # Now match with database records\n    print(\"\\n\" + \"=\"*100)\n    print(\"DATABASE MAPPING\")\n    print(\"=\"*100)\n    \n    # These are the UUIDs we know exist in the database\n    # (from the previous debug output with the normalized UUID format)\n    known_db_uuids = {\n        'd3ecc574-b122-59d3-b0e2-9211c24d72f4': 'Living Shorelines Australia',\n        '83d737cb-9ffa-5576-9d89-1de509304e6e': 'Remote sensing Giant Kelp',\n        'd32ccbe1-d151-53ee-a6b4-dcf10cbc0eb5': 'Baseline coastal estuarine',\n        # ... etc\n    }\n    \n    # The filesystem UUIDs (from directory names) appear to be AODN catalogue UUIDs\n    # which are DIFFERENT from the database UUIDs\n    print(f\"\\nFilesystem UUIDs (from AODN directory names): {len(results)}\")\n    print(f\"Known database UUIDs: {len(known_db_uuids)}\")\n    print(f\"\\nThese appear to be DIFFERENT UUID systems:\")\n    print(f\"  - Filesystem: AODN catalogue UUIDs\")\n    print(f\"  - Database: Internal application UUIDs\")\n    print(f\"\\nMapping strategy: Use dataset titles to link them.\")\n    \n    # Show mapping examples\n    print(\"\\n\" + \"=\"*100)\n    print(\"EXAMPLE MAPPINGS BY DATASET TITLE\")\n    print(\"=\"*100)\n    \n    title_map = {\n        'Australian Chlorophyll a Database': 'The Australian Chlorophyll a Database (1965 - 2017)',\n        'Australian Phytoplankton Database': 'The Australian Phytoplankton Database (1844 - ongoing)',\n        'Seagrass': 'Australian Seagrass distribution',\n        'Baseline coastal': 'Baseline coastal and estuarine condition',\n        'Chlorophyll sampling': 'Chlorophyll sampling in coastal waters',\n        'Nutrient sampling': 'Nutrient sampling in coastal waters',\n        'Oceanography sampling': 'Oceanography sampling in coastal waters',\n        'Phytoplankton sampling': 'Phytoplankton sampling in coastal waters',\n        'Pigment sampling': 'Pigment sampling in coastal waters',\n        'Rocky reef': 'Condition of rocky reef communities',\n        'Zooplankton': 'Zooplankton sampling in coastal waters',\n        'Nearshore temperature': 'Nearshore temperature monitoring',\n        'Ocean acidification': 'Ocean acidification historical reconstruction',\n    }\n    \n    for result in results[:5]:\n        print(f\"\\n{result['uuid']} ({result['dataset_dir']})\")\n        print(f\"  Title: {result['title']}\")\n\nif __name__ == '__main__':\n    main()\n